{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809fb2c2",
   "metadata": {},
   "source": [
    "## Bagging and Random Forest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698cf9dd",
   "metadata": {},
   "source": [
    "\n",
    "Using ensemble methods can greatly improve the results achieved with weak machine learning algorithms, also called weak learners. Ensemble methods achieve better performance by aggregating the results of many statistically independent models. This process averages out the errors and produces a final better prediction.\n",
    "\n",
    "In this lab you will work with a widely used ensemble method known as bootstrap aggregating or simply bagging. Bagging follows a simple procedure:\n",
    "\n",
    "* N learners (machine learning models) are defined.\n",
    "* N subsamples of the training data are created by Bernoulli sampling with replacement.\n",
    "* The N learners are trained on the subsamples of the training data.\n",
    "* The ensemble is scored by averaging, or taking a majority vote, of the predictions from the N learners.\n",
    "\n",
    "Classification and regression tree models are most typically used with bagging methods. The most common such algorithm is know as the random forest. The random forest method is highly scalable and generally produces good results, even for complex problems.\n",
    "\n",
    "Classification and regression trees tend to be robust to noise or outliers in the training data. This is true for the random forest algorithm as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b997132",
   "metadata": {},
   "source": [
    "Example: Creditcard dataset\n",
    "\n",
    "\n",
    "As a second example you will use credit card data to find fraud\n",
    "\n",
    "* In this lab we implement Random forest algorithm on crididt card information dataset.\n",
    "\n",
    "Now, you will try a more complex example using the credit scoring data. You will use the prepared data which had the following preprocessing:\n",
    "\n",
    "* Cleaning missing values.\n",
    "* Aggregating categories of certain categorical variables.\n",
    "* Encoding categorical variables as binary dummy variables.\n",
    "* Standardizing numeric variables.\n",
    "* Execute the code in the cell below to load the features and labels as numpy arrays for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b010b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38f1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60394a05",
   "metadata": {},
   "source": [
    "Nested cross validation is used to estimate the optimal hyperparameters and perform model selection for the random forest model. Since random forest models are efficient to train, 10 fold cross validation is used. Execute the code in the cell below to define inside and outside fold objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2801a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b4de2",
   "metadata": {},
   "source": [
    "The code in the cell below estimates the best hyperparameters using 10 fold cross validation. There are a few points to note here:\n",
    "\n",
    "1. In this case, a grid of two hyperparameters is searched:\n",
    "    \n",
    "        * max_features determines the maximum number of features used to determine the splits. Minimizing the number of features can prevent model over-fitted by induces bias.\n",
    "        \n",
    "        * min_samples_leaf determines the minimum number of samples or leaves which must be on each terminal node of the tree. Maintaining the minimum number of samples per terminal node is a \"regularization method\". Having too few samples on terminal leaves allows the model training to memorize the data, leading to high variance. Forcing too many samples on the terminal nodes leads to biased predictions.\n",
    "        \n",
    "2. Since there is a class imbalance and a difference in the cost to the bank of misclassification of a bad credit risk customer, the \"balanced\" argument is used. The balanced argument ensures that the subsamples used to train each tree have balanced cases.\n",
    "3. The model is fit on each set of hyperparameters from the grid.\n",
    "4. The best estimated hyperparameters are printed.\n",
    "\n",
    "Notice that the model uses regularization rather than feature selection. The hyperparameter search is intended to optimize the level of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a39933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"max_features\": [2, 3, 5, 10, 15], \"min_samples_leaf\":[3, 5, 10, 20]}\n",
    "## Define the random forest model\n",
    "nr.seed(3456)\n",
    "rf_clf = RandomForestClassifier(class_weight = \"balanced\") # class_weight = {0:0.33, 1:0.67}) \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "rf_clf = ms.GridSearchCV(estimator = rf_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "rf_clf.fit(Features, Labels)\n",
    "print(rf_clf.best_estimator_.max_features)\n",
    "print(rf_clf.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14d6b7",
   "metadata": {},
   "source": [
    "Now, you will run the code in the cell below to perform the outer cross validation of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82b5e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.778\n",
      "SDT of the metric       = 0.045\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.782\n",
      "Fold  2    0.728\n",
      "Fold  3    0.704\n",
      "Fold  4    0.739\n",
      "Fold  5    0.789\n",
      "Fold  6    0.828\n",
      "Fold  7    0.772\n",
      "Fold  8    0.864\n",
      "Fold  9    0.806\n",
      "Fold 10    0.765\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(rf_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef18be7",
   "metadata": {},
   "source": [
    "Examine these results. Notice that the standard deviation of the mean of the AUC is more than an order of magnitude smaller than the mean. This indicates that this model is likely to generalize well.\n",
    "\n",
    "Now, you will build and test a model using the estimated optimal hyperparameters. As a first step, execute the code in the cell below to create training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce93ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f71ab",
   "metadata": {},
   "source": [
    "The code in the cell below defines a random forest model object using the estimated optimal model hyperparameters and then fits the model to the training data. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0738a675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features=3,\n",
       "                       min_samples_leaf=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(1115)\n",
    "rf_mod = RandomForestClassifier(class_weight = \"balanced\", \n",
    "                                max_features = rf_clf.best_estimator_.max_features, \n",
    "                                min_samples_leaf = rf_clf.best_estimator_.min_samples_leaf) \n",
    "rf_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224cff63",
   "metadata": {},
   "source": [
    "As expected, the hyperparemeters of the random forest model object reflect those specified.\n",
    "\n",
    "The code in the cell below scores and prints evaluation metrics for the model, using the test data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee240e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       152                60\n",
      "Actual negative        21                67\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.80\n",
      "Macro precision 0.70\n",
      "Macro recall    0.74\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.88          0.53\n",
      "Recall       0.72          0.76\n",
      "F1           0.79          0.62\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = rf_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce397fac",
   "metadata": {},
   "source": [
    "Overall, these performance metrics look quite good. A large majority of negative (bad credit) cases are identified at the expense of significant false positives. The reported AUC is within a standard deviation of the figure obtained with cross validation indicating that the model is generalizing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb24db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
